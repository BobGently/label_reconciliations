{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the expanded csv file from the JSON output and prepares it for the providers. Main ideas are:\n",
    "\n",
    "1. remove user name information only keep the extended_user_id column will have a user ID number \n",
    "2. Sort the entire set by classification ID\n",
    "3. Keep the URL for the providers\n",
    "4. Keep skips in \n",
    "5. Labels are set in a few ways:\n",
    "    * Pull Down Menu example:\n",
    "    T1_select_label_1 - Country - new header\n",
    "    T1_option_1 - T/F -- will be true if pulled an answer from available options, for pull down menus False could mean blank or wrote in an answer other than those available. \n",
    "    T1_value_1 - numerical Value associated with selection\n",
    "    T1_label_1 - actual selection, keep this colum\n",
    "    \n",
    "    To do:  ISO format for dates?\n",
    "    United States of America -> United States\n",
    "    For Insect Data include transcriber information: Created At: Started At: Finished At:\n",
    "    Insect data add in End Date Collected: \n",
    "    \n",
    " \n",
    " SENEREC - do dates like   XXXX-XX-XX\n",
    " for SENEREC and CALBUG add in 00 for missing\n",
    " \n",
    " \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from dateutil import parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def date_parser(day,month,year):\n",
    "    date=()\n",
    "    old_date=()\n",
    "    iso_date=()\n",
    "    if not day:\n",
    "        day='blank-day'\n",
    "        old_day='00'\n",
    "        iso_day='00'\n",
    "    if day == 'Not shown':\n",
    "        day='blank-day'\n",
    "        old_day='00'\n",
    "        iso_day='00'\n",
    "    if day == 'Not Shown':\n",
    "        day='blank-day'\n",
    "        old_day='00'\n",
    "        iso_day='00'\n",
    "    if day is not 'blank-day':\n",
    "    #    print(day)\n",
    "        day=day.zfill(2)\n",
    "        old_day=day.zfill(2)\n",
    "        iso_day=day.zfill(2)\n",
    "    #    print(day,old_day,iso_day)\n",
    "    if not month:\n",
    "        month='blank-month'\n",
    "        old_month='00'\n",
    "        iso_month='00'\n",
    "    if month == 'Not shown':\n",
    "        month='blank-month'\n",
    "        old_month='00'\n",
    "        iso_month='00'\n",
    "    if month == 'Not Shown':\n",
    "        month='blank-month'\n",
    "        old_month='00'\n",
    "        iso_month='00'\n",
    "    if month is not 'blank-month':\n",
    "        month = month[:2].zfill(2)\n",
    "        old_month = month[:2].zfill(2)\n",
    "        iso_month = month[:2].zfill(2)\n",
    "    if not year:\n",
    "        year='blank-year'\n",
    "        old_year='0000'\n",
    "        iso_year='0000'\n",
    "    if year == 'Not shown':\n",
    "        year='blank-year'\n",
    "        old_year='0000'\n",
    "        iso_year='0000'\n",
    "    if year == 'Not Shown':\n",
    "        year='blank-year'\n",
    "        old_year='0000'\n",
    "        iso_year='0000'\n",
    "    if year is not 'blank-year':\n",
    "        year = year[:4].zfill(4)\n",
    "        old_year = year[:4].zfill(4)\n",
    "        iso_year = year[:4].zfill(4)\n",
    "    old_date = \"/\".join([old_day,old_month,old_year])\n",
    "    iso_date = \"-\".join([iso_year,iso_month,iso_day])\n",
    "    #print(old_date,iso_date)\n",
    "    return (date,old_date,iso_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_csv(file_name, index):\n",
    "    with open(file_name, 'r') as f:\n",
    "        readit = csv.reader(f)\n",
    "        all_data = list(readit)\n",
    "        header = all_data[0]\n",
    "        the_data = all_data[1:]\n",
    "    the_data.sort(key=itemgetter(index))\n",
    "    with open(file_name, 'w') as f:\n",
    "        writeit = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "        writeit.writerow(header)\n",
    "        writeit.writerows(the_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_butterfly_Butterfly_New(in_file_name, out_file_name):\n",
    "     with open(in_file_name, 'r') as in_file, open(out_file_name, 'w') as out_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        headers = []\n",
    "        for row in reader:\n",
    "            new_row = OrderedDict()\n",
    "            new_row['Subject_ID']=row['subject_ids']\n",
    "            new_row['Expedition_Name']=row['workflow_name']\n",
    "            #new_row['Classification_ID']=row['classification_id']\n",
    "            new_row['Transcription_Date']=row['created_at']\n",
    "            #new_row['Collection Code']=row['collectionCode']\n",
    "            #new_row['Institution Code']=row['institutionCode']\n",
    "            new_row['User_Id']=row['extended_user_id']\n",
    "            new_row['Genus']=row['genus']\n",
    "            new_row['Scientific_Name']=row['scientificName']\n",
    "            new_row['Collected_By']=row['T6_value']\n",
    "            year = (row['T10_label_1'])\n",
    "            month = (row['T8_label_1'])\n",
    "            day = (row['T9_label_1'])\n",
    "            date,old_date,iso_date = date_parser(day,month,year)\n",
    "            #print(iso_date)\n",
    "            new_row['Date']=iso_date\n",
    "            new_row['Country']=row['T1_label_1']\n",
    "            new_row['State/Province']=row['T1_label_2']\n",
    "            new_row['County']=row['T1_label_3']\n",
    "            new_row['Locality']=row['T3_value']\n",
    "            new_row['Other Notes']=row['T12_value']\n",
    "            new_row['Sex']=row['T13_label_1']\n",
    "            new_row['Latitude']=row['T16_value']\n",
    "            new_row['Longitude']=row['T17_value']\n",
    "            new_row['Elevation']=row['T18_value']\n",
    "            new_row['Other Notes']=row['T12_value']\n",
    "            new_row['DNA_Voucher_Label']=row['T20_value']\n",
    "            if not headers:\n",
    "                headers = new_row.keys()\n",
    "                writer  = csv.DictWriter(out_file, headers)\n",
    "                writer.writeheader()\n",
    "            writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_butterfly_Butterfly_New('expandedNfN_2054.csv', 'PROVIDER_Butterfly_2054.csv')\n",
    "sort_csv('PROVIDER_Butterfly_2054.csv', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def read_json_expanded_PS_CalbugBee(in_file_name, out_file_name):\n",
    "    with open(in_file_name, 'r') as in_file, open(out_file_name, 'w') as out_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        headers = []\n",
    "        for row in reader:\n",
    "            new_row = OrderedDict()\n",
    "            new_row['Subject_Id']=row['subject_ids']\n",
    "            new_row['Catalog Number']=row['catalogNumber']\n",
    "            new_row['Collection Code']=row['collectionCode']\n",
    "            new_row['Institution Code']=row['institutionCode']\n",
    "            new_row['User_Id']=row['extended_user_id']\n",
    "            new_row['Classification_Created']=row['created_at']\n",
    "            new_row['Classification_Started']=row['classification_started_at']\n",
    "            new_row['Classification_Finished']=row['classification_finished_at']\n",
    "            new_row['Genus']=row['genus']\n",
    "            new_row['Scientific Name']=row['scientificName']\n",
    "            country = row['T1_label_1']\n",
    "            if 'United States' in country:\n",
    "                country = 'United States'\n",
    "            new_row['Country']=country\n",
    "            #new_row['Country']=row['T1_label_1']\n",
    "            new_row['State/Province']=row['T1_label_2']\n",
    "            new_row['County']=row['T1_label_3']\n",
    "            new_row['Locality']=row['T3_value']\n",
    "            new_row['Other Notes']=row['T4_value']\n",
    "            new_row['Collector']=row['T6_value']\n",
    "            Byear = (row['T10_label_1'])\n",
    "            Bmonth = (row['T8_label_1'])\n",
    "            Bday = (row['T9_label_1'])\n",
    "            Bdate,B_old_date,B_iso_date = date_parser(Bday,Bmonth,Byear)\n",
    "            new_row['Begin Date']=B_old_date\n",
    "            new_row['Begin Date ISO']=B_iso_date\n",
    "            Emonth=row['T13_label_1']\n",
    "            Eday=row['T14_label_1']\n",
    "            Eyear=row['T15_label_1']\n",
    "            Edate,E_old_date,E_iso_date, = date_parser(Eday,Emonth,Eyear)\n",
    "    #       print(B_old_date,E_old_date)\n",
    "            new_row['End Date']=E_old_date\n",
    "            new_row['End Date ISO']=E_iso_date\n",
    "            new_row['Provider ImageName']=row['provider_imageName']\n",
    "            new_row['Provider imageURL']=row['provider_imageURL']\n",
    "            new_row['Portal URL']=row['references']\n",
    "            #new_row['Zooniverse URL']=row['zooniverse_URL']\n",
    "            if not headers:\n",
    "                headers = new_row.keys()\n",
    "                writer  = csv.DictWriter(out_file, headers)\n",
    "                writer.writeheader()\n",
    "            writer.writerow(new_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_json_expanded_PS_CalbugBee('expandedNfN_2045.csv', 'PROVIDER_PS_CalbugBee.csv')\n",
    "sort_csv('PROVIDER_PS_CalbugBee.csv', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json_expanded_FLmints(in_file_name, out_file_name):\n",
    "    with open(in_file_name, 'r') as in_file, open(out_file_name, 'w') as out_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        headers = []\n",
    "        for row in reader:\n",
    "            new_row = OrderedDict()\n",
    "            new_row['Expedition_Name']=row['workflow_name']\n",
    "            new_row['Transcription Date']=row['created_at']\n",
    "            new_row['Subject Id']=row['subject_ids']\n",
    "            new_row['Catalog Number']=row['catalogNumber']\n",
    "            new_row['Collection Code']=row['collectionCode']\n",
    "            new_row['Institution Code']=row['institutionCode']\n",
    "            new_row['User Id']=row['extended_user_id']\n",
    "            new_row['Scientific Name']=row['T2_value']\n",
    "        #    new_row['Country']=row['T1_label_1']\n",
    "        #    new_row['State/Province']=row['T1_label_2']\n",
    "            new_row['County']=row['T12_label_1']\n",
    "            new_row['Location']=row['T3_value']\n",
    "            new_row['Habitat and Description']=row['T4_value']\n",
    "            new_row['Collected By']=row['T6_value']\n",
    "            new_row['Collector Number']=row['T7_value']\n",
    "            year = (row['T10_label_1'])\n",
    "            month = (row['T8_label_1'])\n",
    "            day = (row['T9_label_1'])\n",
    "            date,old_date,iso_date = date_parser(day,month,year)\n",
    "            new_row['Date']=iso_date\n",
    "            new_row['Provider ImageName']=row['provider_imageName']\n",
    "            new_row['Provider imageURL']=row['provider_imageURL']\n",
    "            new_row['Portal URL']=row['references']\n",
    "            #new_row['Zooniverse URL']=row['zooniverse_URL']\n",
    "            if not headers:\n",
    "                headers = new_row.keys()\n",
    "                writer  = csv.DictWriter(out_file, headers)\n",
    "                writer.writeheader()\n",
    "            writer.writerow(new_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_json_expanded_FLmints('expandedNfN_1930.csv', 'PROVIDER_WeDigFLPlants_Mints.csv')\n",
    "sort_csv('PROVIDER_WeDigFLPlants_Mints.csv', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json_expanded_LaurelsofFL(in_file_name, out_file_name):\n",
    "    with open(in_file_name, 'r') as in_file, open(out_file_name, 'w') as out_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        headers = []\n",
    "        for row in reader:\n",
    "            new_row = OrderedDict()\n",
    "            new_row['Subject_Id']=row['subject_ids']\n",
    "            new_row['Catalog Number']=row['catalogNumber']\n",
    "            new_row['Collection Code']=row['collectionCode']\n",
    "            new_row['Institution Code']=row['institutionCode']\n",
    "            new_row['User_Id']=row['extended_user_id']\n",
    "            new_row['Scientific Name']=row['T2_value']\n",
    "            country=row['T1_label_1']\n",
    "            new_row['Country']=country\n",
    "            new_row['State/Province']=row['T1_label_2']\n",
    "            new_row['County']=row['T1_label_3']\n",
    "            new_row['Location']=row['T3_value']\n",
    "            new_row['Habitat and Description']=row['T4_value']\n",
    "            new_row['Collected By']=row['T6_value']\n",
    "            new_row['Collector Number']=row['T7_value']\n",
    "            year = (row['T10_label_1'])\n",
    "            month = (row['T8_label_1'])\n",
    "            day = (row['T9_label_1'])\n",
    "            date,old_date,iso_date = date_parser(day,month,year)\n",
    "             new_row['Provider ImageName']=row['provider_imageName']\n",
    "            new_row['Provider imageURL']=row['provider_imageURL']\n",
    "            new_row['Portal URL']=row['references']\n",
    "            new_row['Zooniverse URL']=row['zooniverse_URL']\n",
    "            if not headers:\n",
    "                headers = new_row.keys()\n",
    "                writer  = csv.DictWriter(out_file, headers)\n",
    "                writer.writeheader()\n",
    "            writer.writerow(new_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_json_expanded_LaurelsofFL('expandedNfN_1931.csv', 'PROVIDER_WeDigFLPlants_Laurels.csv')\n",
    "sort_csv('PROVIDER_WeDigFLPlants_Laurels.csv', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
