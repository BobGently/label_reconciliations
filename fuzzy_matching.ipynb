{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Reconciliations with Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from dateutil import parser\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "## look at comprehensions dictionary set can filter lists\n",
    "## look at itertools combinations() for the all on all comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code for reconciliations of free text transcript fields.  Have defined a number of fields and a few different methods for each field type. First code for reading in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_clean_data(file_name):\n",
    "    data = {}\n",
    "    with open(file_name, 'r') as in_file:\n",
    "        reader = csv.DictReader(in_file)\n",
    "        headers = reader.fieldnames\n",
    "        for row in reader:\n",
    "            key = row['filename']\n",
    "            #print(key)\n",
    "            xscripts = data.get(key, [])\n",
    "            #print(xscripts)\n",
    "            xscripts.append(row)\n",
    "            data[key] = xscripts\n",
    "            #if reader.line_num >10: \n",
    "            #    break\n",
    "        print(reader.line_num)\n",
    "    return data, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "['',\n",
      " '',\n",
      " 'subject_id',\n",
      " 'filename',\n",
      " 'user_name',\n",
      " 'created_at',\n",
      " 'Collected by',\n",
      " 'Collection date',\n",
      " 'Collector Number',\n",
      " 'Country',\n",
      " 'County',\n",
      " 'Habitat',\n",
      " 'Description',\n",
      " 'Species',\n",
      " 'State',\n",
      " 'Skip',\n",
      " '',\n",
      " '']\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "data,headers = read_clean_data('Brit_41transcriptsforhabitat.csv')\n",
    "pprint(headers)\n",
    "print(len(data))\n",
    "#pprint(data['BRIT118000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Scientific Name:**  \n",
    "    - _Method_: Fuzzy match on tokens in order  (fuzz_set_ratio) -- Will take a subset as a match if one entirely exists in the other \n",
    "    \n",
    "    \n",
    "    - a. if 100 match on tokens for all 3 - full agree --> 2. \n",
    "    - b. if 100 match on 2 of 3 - maj rule --> 2.\n",
    "    - c. If <100 match on tokens, report two highest scoring and flag --> Done.\n",
    "\n",
    "- 2.To deal with varieties and hybrids (x in plant data) report the longest (string or token umber?) \n",
    "\n",
    "    -only issue with this is getting extraneous information (e.g. 'Hypericum stragulum A. & R.' '(Hypericum  hypericoides) Jesse M. shaver'\n",
    "  \n",
    "    - possibly remove parenthesies?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLAGS = ['all agree', 'Majority Rules','only a single transcript','more than 1 unique answer','all are blank']\n",
    "\n",
    "def recon_scientific_name(data,field):\n",
    "    flags={}\n",
    "    allagree=0\n",
    "    notallagree=0\n",
    "    for key, xscripts in data.items():\n",
    "        ### first determine if any are blank and add the non blank to a list to compare. \n",
    "        my_len = len(xscripts)\n",
    "        lst=[]\n",
    "        for x in range(my_len):\n",
    "            if xscripts[x][field]:\n",
    "                lst.append(xscripts[x][field])\n",
    "        my_newlen = len(lst)\n",
    "    #    print(key,\"The original length %s new length %s.\" %(my_len,my_newlen))\n",
    "    #   find the ones that are all blank and flag them\n",
    "        if not len(lst):\n",
    "        #   totally empty add empty flag\n",
    "            print(key,\"Zero Loop.The length %s new length %s.\" %(my_len,my_newlen))\n",
    "        elif len(lst) == 1:\n",
    "        #   Only have one add one flag and take what we have but make sure not empty\n",
    "            print(key,\"One Loop.The length %s new length %s.\" %(my_len,my_newlen))\n",
    "        else:\n",
    "            my_scorelst=[] \n",
    "            print(key,\"There are %d filled in\" %(my_newlen))\n",
    "            for x in range(my_newlen):\n",
    "                for y in range(x+1,my_newlen):\n",
    "                #    print(lst[x],lst[y])\n",
    "                    score = fuzz.token_set_ratio(lst[x],lst[y])\n",
    "                #    print(score)\n",
    "                    my_scorelst.append(score)\n",
    "        hundreds=0\n",
    "        for i in range(len(my_scorelst)):\n",
    "            if my_scorelst[i] == 100:\n",
    "                hundreds+=1\n",
    "            #    print(hundreds)\n",
    "        if len(my_scorelst) == hundreds:  #all scores eq 100\n",
    "        #    flags[key] = dict(flag=FLAGS[0])\n",
    "            allagree+=1\n",
    "        #    print(key,\"All agree num hundreds %d equals length %d.\" %(hundreds,(len(my_scorelst))))\n",
    "            ## get length of each of the strings and keep the longest\n",
    "            my_biglen=0\n",
    "            for x in range(my_len):\n",
    "                name=xscripts[x][field]\n",
    "                ln = len(name)\n",
    "            #    print(\"the length of %s is %s.\" %(name,ln))\n",
    "                if ln > my_biglen:\n",
    "                    keep=name\n",
    "                    my_biglen = ln\n",
    "                #    dict(ScienName[key]:name)\n",
    "                #   Need a dictionary of dictionaries? key by subject and the one to keep plus a flag?\n",
    "        #    print(key,keep,my_biglen)\n",
    "        else:\n",
    "            print(key,hundreds)\n",
    "            notallagree+=1\n",
    "            if hundreds == 1:\n",
    "                print(key, \"There is only one hundred\")\n",
    "                for x in range(my_newlen):\n",
    "                    for y in range(x+1,my_newlen):\n",
    "                    #    print(lst[x],lst[y:q])\n",
    "                        score = fuzz.token_set_ratio(lst[x],lst[y])\n",
    "                        if score == 100:\n",
    "                            \n",
    "#    print(score)\n",
    "                #    my_scorelst.append(score)\n",
    "\n",
    "    print(allagree,notallagree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIT118088 There are 4 filled in\n",
      "BRIT118088 3\n",
      "BRIT118130 There are 2 filled in\n",
      "BRIT118136 There are 4 filled in\n",
      "BRIT118181 There are 3 filled in\n",
      "BRIT118158 There are 3 filled in\n",
      "BRIT118159 There are 3 filled in\n",
      "BRIT118095 There are 3 filled in\n",
      "BRIT118115 There are 4 filled in\n",
      "BRIT118160 There are 3 filled in\n",
      "BRIT118141 There are 3 filled in\n",
      "BRIT118152 There are 3 filled in\n",
      "BRIT118009 There are 3 filled in\n",
      "BRIT118009 0\n",
      "BRIT118087 There are 4 filled in\n",
      "BRIT118000 There are 3 filled in\n",
      "BRIT118015 There are 3 filled in\n",
      "BRIT118171 There are 3 filled in\n",
      "BRIT118155 There are 3 filled in\n",
      "BRIT118134 There are 3 filled in\n",
      "BRIT118134 1\n",
      "BRIT118134 There is only one hundred\n",
      "BRIT118122 There are 3 filled in\n",
      "BRIT118122 0\n",
      "BRIT118119 There are 3 filled in\n",
      "BRIT118119 1\n",
      "BRIT118119 There is only one hundred\n",
      "BRIT118051 There are 3 filled in\n",
      "BRIT118111 There are 3 filled in\n",
      "BRIT118039 There are 4 filled in\n",
      "BRIT118007 There are 3 filled in\n",
      "BRIT118116 There are 4 filled in\n",
      "BRIT118116 3\n",
      "BRIT118011 There are 3 filled in\n",
      "BRIT118105 There are 3 filled in\n",
      "BRIT118094 There are 4 filled in\n",
      "BRIT118090 There are 4 filled in\n",
      "BRIT118093 There are 3 filled in\n",
      "BRIT118133 There are 3 filled in\n",
      "BRIT118165 There are 3 filled in\n",
      "BRIT118145 There are 2 filled in\n",
      "BRIT118145 0\n",
      "BRIT118182 There are 4 filled in\n",
      "BRIT118182 3\n",
      "BRIT118183 There are 3 filled in\n",
      "BRIT118153 There are 4 filled in\n",
      "BRIT118153 3\n",
      "BRIT118113 There are 3 filled in\n",
      "BRIT118163 There are 2 filled in\n",
      "BRIT118103 There are 4 filled in\n",
      "BRIT118029 One Loop.The length 4 new length 1.\n",
      "BRIT118718 Zero Loop.The length 5 new length 0.\n",
      "32 9\n",
      "[{'': 'Sat, 28 Nov 2015 22:34:44 GMT',\n",
      "  'Collected by': 'Sidney McDaniel',\n",
      "  'Collection date': '9/27/65',\n",
      "  'Collector Number': '7004',\n",
      "  'Country': 'United States',\n",
      "  'County': 'Chilton',\n",
      "  'Description': '11 miles southeast of Maplesville',\n",
      "  'Habitat': 'fall-line sand hill, longleaf pine-turkey oak, 35ft tree',\n",
      "  'Skip': '',\n",
      "  'Species': 'Quercus margaretta ashe',\n",
      "  'State': 'AL',\n",
      "  'created_at': '2015-11-28 22:34:48 UTC',\n",
      "  'filename': 'BRIT118130',\n",
      "  'subject_id': '561ab9b462b39a5cfdfccbc0',\n",
      "  'user_name': 'Angelikap'},\n",
      " {'': 'Thu, 22 Oct 2015 16:37:31 GMT',\n",
      "  'Collected by': 'Sidney McDaniel',\n",
      "  'Collection date': '9/27/65',\n",
      "  'Collector Number': '7004',\n",
      "  'Country': 'United States',\n",
      "  'County': 'Chilton',\n",
      "  'Description': '11 miles southwest of Maplesville',\n",
      "  'Habitat': 'fall-line sand hill, longleaf pine-turkey oak, 35 ft. tree',\n",
      "  'Skip': '',\n",
      "  'Species': 'Quercus margaretta',\n",
      "  'State': 'AL',\n",
      "  'created_at': '2015-10-22 16:37:31 UTC',\n",
      "  'filename': 'BRIT118130',\n",
      "  'subject_id': '561ab9b462b39a5cfdfccbc0',\n",
      "  'user_name': 'not-logged-in-4e50c019d76fc93f758d42de2bf81552'},\n",
      " {'': 'Sat, 24 Oct 2015 18:31:08 GMT',\n",
      "  'Collected by': '',\n",
      "  'Collection date': '',\n",
      "  'Collector Number': '',\n",
      "  'Country': '',\n",
      "  'County': '',\n",
      "  'Description': '',\n",
      "  'Habitat': '',\n",
      "  'Skip': 'TRUE',\n",
      "  'Species': '',\n",
      "  'State': '',\n",
      "  'created_at': '2015-10-24 18:31:11 UTC',\n",
      "  'filename': 'BRIT118130',\n",
      "  'subject_id': '561ab9b462b39a5cfdfccbc0',\n",
      "  'user_name': 'Peter Fritsch'}]\n"
     ]
    }
   ],
   "source": [
    "test = recon_scientific_name(data,'Species')\n",
    "pprint(data['BRIT118130'])\n",
    "#pprint(flags['BRIT118130'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Collected By:**  \n",
    "    - _Method_: fuzz.token_sort_ratio() will deal with out of order names and allows for order difference. Fuzzy wuzzy deals will flag punctuation differences (e.g.  A.I  and AI are the same token), just NEED TO CHECK that it deals with capitalization.\n",
    "    \n",
    "    \n",
    "    - a. if 100 match on tokens for all 3 - full agree - show original form.\n",
    "    - b. if 100 match on 2 of 3 - maj. rule - show original form\n",
    "    - c. if less than 100 match on token, [report two highest scoring in original form] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def collected_by():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Habitat and Description:** \n",
    "\n",
    "    -**General Idea**:  _Want the label exactly as written._ \n",
    "        Instructions to transcribers were to write the label exactly as is. Therefore the first step is to look for exact matches. \n",
    "        If there is not an exact match want to maximize information while reducing interpretations. Generally if people do not write what is on the label that is because they have expanded an abbreviation (e.g. hwy --> highway) therefore we want the shortest string length. However, we want the labels with the longest token length to ensure that all words are accounted for.\n",
    "        Main issues with these fields is that the inforamtion often can be found in both fields. For example habitat information writted in the description column and vice versa. Therefore we will first find the best label within each category and then compare across categories.\n",
    "    \n",
    "    -**Within Category Method**: _fuzz.token\\_set\\_ratio_  THEN _fuzz.token_sort_ratio_ -- first looking to see if all the words in one are present in another - would give 100 match. Second look to see the score of the sort ratio - checks the order.\n",
    "    \n",
    "       - a. if all 100s on the set then check on the sort and if 100 choose that comparison. --> go to 2.\n",
    "       - b. if not all 100s find  -- NEED MORE LOGIC HERE>\n",
    "\n",
    "       2. do an exact match.  --> Use the one with the shortest string length and longest word length if there is a difference.  \n",
    "       \n",
    "    -**Across Category Method**:  Possibly dont do this. There are reasons why we might want information in both categories..\n",
    "        - THEN just taking frequency based approach for both habitat and location and secondarily - ask if location and habitat match too much, significant overlap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "[(100, 0, 1), (100, 0, 2), (100, 1, 2)]\n"
     ]
    }
   ],
   "source": [
    "#pprint(data['BRIT118113'])\n",
    "test = data['BRIT118160']\n",
    "#pprint(test)\n",
    "#lst=[]\n",
    "l = len(test)\n",
    "pprint(l)\n",
    "n=len(test)\n",
    "pprint(n)\n",
    "lst=[]\n",
    "for x in range(n):\n",
    "    for y in range(x+1,n):\n",
    "        score = fuzz.token_set_ratio(test[x]['Habitat'],test[y]['Habitat'])\n",
    "        ### for all 100 take the one with the more words\n",
    "        # if there are different lengths report the flag , most likely there was a shorter transcript in this set. \n",
    "        # \n",
    "        #score2 = fuzz.token_sort_ratio(test[x]['Habitat'],test[y]['Habitat'])\n",
    "        #print(score,x,y)\n",
    "        lst.append((score,x,y))\n",
    "        \n",
    "slst=sorted(lst,key=lambda x: x[0], reverse=True)\n",
    "\n",
    "pprint(slst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reconcile_text_fields(file_name,field):\n",
    "    for key, xscripts in data.items():\n",
    "        l = len(xscripts)\n",
    "        #for x in range(l-1):\n",
    "            #if not xscripts[l][field]:\n",
    "            #    print(xscripts[l][field])\n",
    "            #    flag='all blank'\n",
    "            #    print(xscripts[field])\n",
    "        #counts = Counter([xscripts[field] for x in xscripts if x[field] and x[field].lower()])\n",
    "        #if not len(counts):\n",
    "        #    flags[key] = dict(flag=FLAGS[4], value='', top_count=0, blank_count=len(xscripts))\n",
    "        #l = len(xscripts)\n",
    "        for x in range(n):\n",
    "            for y in range(x+1,n):\n",
    "                score = fuzz.token_set_ratio(xscripts[x][field],xscripts[y][field])\n",
    "                print(key,score,x,y)\n",
    "        #break\n",
    "    #    n = len(test)\n",
    "    #    pprint(test)\n",
    "    return(key)\n",
    "    #return (scores,comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIT118134 100 0 1\n",
      "BRIT118134 100 0 2\n",
      "BRIT118134 100 1 2\n",
      "BRIT118051 100 0 1\n",
      "BRIT118051 100 0 2\n",
      "BRIT118051 100 1 2\n",
      "BRIT118141 82 0 1\n",
      "BRIT118141 91 0 2\n",
      "BRIT118141 100 1 2\n",
      "BRIT118116 100 0 1\n",
      "BRIT118116 100 0 2\n",
      "BRIT118116 100 1 2\n",
      "BRIT118093 100 0 1\n",
      "BRIT118093 100 0 2\n",
      "BRIT118093 100 1 2\n",
      "BRIT118000 100 0 1\n",
      "BRIT118000 100 0 2\n",
      "BRIT118000 100 1 2\n",
      "BRIT118119 100 0 1\n",
      "BRIT118119 86 0 2\n",
      "BRIT118119 86 1 2\n",
      "BRIT118145 100 0 1\n",
      "BRIT118145 0 0 2\n",
      "BRIT118145 0 1 2\n",
      "BRIT118181 0 0 1\n",
      "BRIT118181 0 0 2\n",
      "BRIT118181 100 1 2\n",
      "BRIT118152 100 0 1\n",
      "BRIT118152 100 0 2\n",
      "BRIT118152 100 1 2\n",
      "BRIT118039 100 0 1\n",
      "BRIT118039 100 0 2\n",
      "BRIT118039 100 1 2\n",
      "BRIT118007 100 0 1\n",
      "BRIT118007 100 0 2\n",
      "BRIT118007 100 1 2\n",
      "BRIT118130 0 0 1\n",
      "BRIT118130 99 0 2\n",
      "BRIT118130 0 1 2\n",
      "BRIT118029 0 0 1\n",
      "BRIT118029 0 0 2\n",
      "BRIT118029 0 1 2\n",
      "BRIT118087 100 0 1\n",
      "BRIT118087 100 0 2\n",
      "BRIT118087 100 1 2\n",
      "BRIT118155 100 0 1\n",
      "BRIT118155 100 0 2\n",
      "BRIT118155 100 1 2\n",
      "BRIT118105 100 0 1\n",
      "BRIT118105 100 0 2\n",
      "BRIT118105 100 1 2\n",
      "BRIT118103 100 0 1\n",
      "BRIT118103 100 0 2\n",
      "BRIT118103 100 1 2\n",
      "BRIT118094 100 0 1\n",
      "BRIT118094 100 0 2\n",
      "BRIT118094 100 1 2\n",
      "BRIT118159 100 0 1\n",
      "BRIT118159 100 0 2\n",
      "BRIT118159 95 1 2\n",
      "BRIT118133 100 0 1\n",
      "BRIT118133 100 0 2\n",
      "BRIT118133 100 1 2\n",
      "BRIT118088 100 0 1\n",
      "BRIT118088 100 0 2\n",
      "BRIT118088 100 1 2\n",
      "BRIT118015 0 0 1\n",
      "BRIT118015 0 0 2\n",
      "BRIT118015 0 1 2\n",
      "BRIT118183 100 0 1\n",
      "BRIT118183 99 0 2\n",
      "BRIT118183 99 1 2\n",
      "BRIT118111 100 0 1\n",
      "BRIT118111 18 0 2\n",
      "BRIT118111 18 1 2\n",
      "BRIT118115 100 0 1\n",
      "BRIT118115 100 0 2\n",
      "BRIT118115 100 1 2\n",
      "BRIT118095 100 0 1\n",
      "BRIT118095 81 0 2\n",
      "BRIT118095 81 1 2\n",
      "BRIT118122 100 0 1\n",
      "BRIT118122 100 0 2\n",
      "BRIT118122 100 1 2\n",
      "BRIT118160 100 0 1\n",
      "BRIT118160 100 0 2\n",
      "BRIT118160 100 1 2\n",
      "BRIT118011 100 0 1\n",
      "BRIT118011 100 0 2\n",
      "BRIT118011 98 1 2\n",
      "BRIT118153 100 0 1\n",
      "BRIT118153 89 0 2\n",
      "BRIT118153 100 1 2\n",
      "BRIT118009 0 0 1\n",
      "BRIT118009 0 0 2\n",
      "BRIT118009 98 1 2\n",
      "BRIT118182 100 0 1\n",
      "BRIT118182 100 0 2\n",
      "BRIT118182 100 1 2\n",
      "BRIT118165 100 0 1\n",
      "BRIT118165 100 0 2\n",
      "BRIT118165 100 1 2\n",
      "BRIT118090 100 0 1\n",
      "BRIT118090 100 0 2\n",
      "BRIT118090 100 1 2\n",
      "BRIT118158 100 0 1\n",
      "BRIT118158 100 0 2\n",
      "BRIT118158 100 1 2\n",
      "BRIT118136 98 0 1\n",
      "BRIT118136 98 0 2\n",
      "BRIT118136 100 1 2\n",
      "BRIT118113 32 0 1\n",
      "BRIT118113 100 0 2\n",
      "BRIT118113 100 1 2\n",
      "BRIT118171 0 0 1\n",
      "BRIT118171 0 0 2\n",
      "BRIT118171 0 1 2\n",
      "BRIT118163 100 0 1\n",
      "BRIT118163 0 0 2\n",
      "BRIT118163 0 1 2\n"
     ]
    }
   ],
   "source": [
    "test = reconcile_text_fields(data,'Habitat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
